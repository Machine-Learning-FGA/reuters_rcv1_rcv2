{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# ==============================================================================\n",
    "# CONSTANTS\n",
    "# ==============================================================================\n",
    "EN_DOCS = 18758 # number of samples of english documents\n",
    "EN_TOKENS = 21531 + 1 # number of features of english documents\n",
    "\n",
    "# Functions\n",
    "def createArray (numRows, numCols, document):\n",
    "    datas = {} \n",
    "    datas['data'] =  np.zeros(shape=(EN_DOCS, EN_TOKENS), dtype='float32')\n",
    "    aux_list = []\n",
    "    for (index, value) in enumerate(document):\n",
    "        doc_splited = value.split(' ')\n",
    "        doc_splited.remove('\\n') # remove end of line character\n",
    "        for y in doc_splited:\n",
    "            splited = y.split(':')\n",
    "            if len(splited) == 1:\n",
    "                aux_list.append(splited[0])\n",
    "            else:\n",
    "                datas['data'][index][int(splited[0])] = float(splited[1])\n",
    "    datas['target'] = np.asarray(aux_list)\n",
    "    return datas\n",
    "\n",
    "# ==============================================================================\n",
    "# Here we can import all files from each path with glob lib using string matcher\n",
    "# If we have opened more than one file we need to map our file_names and create\n",
    "# ==============================================================================\n",
    "# You must have to unconpress the rcv1rcv2aminigoutte.tar.gz to create\n",
    "# rcv1rcv2aminigoutte path with the files\n",
    "#===============================================================================\n",
    "file_names = glob.glob('rcv1rcv2aminigoutte/EN/Index_EN-EN')\n",
    "with open(file_names[0]) as document:\n",
    "    file_read = document.readlines()\n",
    "    \n",
    "# ==============================================================================\n",
    "# ML\n",
    "# ==============================================================================\n",
    "datas = createArray(EN_DOCS, EN_TOKENS, file_read)\n",
    "del(file_read)\n",
    "document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data matrix shape before feature selection: (18758, 21532)\n",
      "Data matrix shape after feature selection: (18758, 3022)\n",
      "Splitting dataset to train and test ones....\n",
      "Fitting KNN classifier....\n",
      "Getting scores....\n",
      "0.5488272921108742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# ==============================================================================\n",
    "# Getting feature and data values\n",
    "# ==============================================================================\n",
    "y = datas['target']\n",
    "X = datas['data']\n",
    "del(datas)\n",
    "\n",
    "# ==============================================================================\n",
    "# Applying feature selection\n",
    "# ==============================================================================\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "print('Data matrix shape before feature selection: ' + str(X.shape))\n",
    "print('Data matrix shape after feature selection: ' + str(X_new.shape))\n",
    "\n",
    "# ==============================================================================\n",
    "# Splitting datasets\n",
    "# ==============================================================================\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "print('Splitting dataset to train and test ones....')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "del(X)\n",
    "del(X_new)\n",
    "\n",
    "# ==============================================================================\n",
    "# Fitting KNN classifier\n",
    "# ==============================================================================\n",
    "print('Fitting KNN classifier....')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# ==============================================================================\n",
    "# Getting \"model\" accuracy.\n",
    "# \"model\" because KNN doesn't explicity learn a model. This classifier chooses\n",
    "# to memorizes the training instances which are subsequently used as \"knowledge\"\n",
    "# on prediction phase (instance-based learning algorithm)\n",
    "# ==============================================================================\n",
    "print('Getting scores....')\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(knn_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
